# app.py
# ğŸ”® ì§€í•˜ì²  ì´ìš© ì˜ˆì¸¡ê¸° (Ridership Predictor)
# - ì…ë ¥: í˜¸ì„ , ì—­, ë‚ ì§œ(â†’ì›”), ì‹œê°„ëŒ€(í•„ìˆ˜), ìš”ì¼(ë°ì´í„°ì— ìˆì„ ë•Œë§Œ)
# - ì¶œë ¥: ì˜ˆìƒ ìŠ¹ì°¨/í•˜ì°¨ ì¸ì› + ê³¼ê±° ë¶„í¬ ë¹„êµ ê·¸ë˜í”„/í‘œ
# - ì‚¬ìš©ë²•: streamlit run app.py
# - CSV ì¸ì½”ë”©: cp949 (ì„œìš¸ì—´ë¦°ë°ì´í„°ê´‘ì¥ ê¸°ë³¸ ë°°í¬ í˜•ì‹)

import os
import re
import io
import gc
import datetime as dt
import numpy as np
import pandas as pd
import streamlit as st

# ML
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Optional: LightGBM
LGBM_AVAILABLE = True
try:
    from lightgbm import LGBMRegressor
except Exception:
    LGBM_AVAILABLE = False
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression

# ---------------------------
# âš™ï¸ Streamlit Page Config
# ---------------------------
st.set_page_config(
    page_title="ğŸ”® ì§€í•˜ì²  ì´ìš© ì˜ˆì¸¡ê¸°",
    page_icon="ğŸš‡",
    layout="wide"
)

st.title("ğŸ”® ì§€í•˜ì²  ì´ìš© ì˜ˆì¸¡ê¸° (Ridership Predictor)")
st.caption("ì„œìš¸ì‹œ ì§€í•˜ì²  í˜¸ì„ Â·ì—­Â·ì‹œê°„ëŒ€ë³„ ìŠ¹í•˜ì°¨ ì¸ì› ë°ì´í„° ê¸°ë°˜ | ì›” ë‹¨ìœ„ ì˜ˆì¸¡")

# ---------------------------
# ğŸ“¥ ë°ì´í„° ë¡œë”©
# ---------------------------
st.sidebar.header("1) ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°")
src_opt = st.sidebar.radio("ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ", ["ë¡œì»¬ ì—…ë¡œë“œ", "ê²½ë¡œ ì…ë ¥(/mnt ë˜ëŠ” GitHub Raw)"], index=0)
default_path = "/mnt/data/station.csv" if os.path.exists("/mnt/data/station.csv") else ""

uploaded_file = None
csv_bytes = None

if src_opt == "ë¡œì»¬ ì—…ë¡œë“œ":
    uploaded_file = st.sidebar.file_uploader("CSV íŒŒì¼ ì„ íƒ (cp949 ì¸ì½”ë”©)", type=["csv"])
    if uploaded_file:
        csv_bytes = uploaded_file.read()
elif src_opt == "ê²½ë¡œ ì…ë ¥(/mnt ë˜ëŠ” GitHub Raw)":
    path = st.sidebar.text_input("CSV ê²½ë¡œ(URL ë˜ëŠ” ë¡œì»¬ ê²½ë¡œ)", value=default_path)
    if path:
        # URLì¼ ìˆ˜ë„ ìˆê³  ë¡œì»¬ì¼ ìˆ˜ë„ ìˆìŒ
        if re.match(r"^https?://", path):
            import requests
            r = requests.get(path)
            r.raise_for_status()
            csv_bytes = r.content
        else:
            with open(path, "rb") as f:
                csv_bytes = f.read()

@st.cache_data(show_spinner=True)
def load_data(csv_bytes: bytes) -> pd.DataFrame:
    # ì„œìš¸ì—´ë¦°ë°ì´í„°ê´‘ì¥ CSVëŠ” cp949ê°€ ê¸°ë³¸. ì‹¤íŒ¨ ì‹œ utf-8ë¡œ ì¬ì‹œë„.
    buf = io.BytesIO(csv_bytes)
    try:
        df = pd.read_csv(buf, encoding="cp949")
    except Exception:
        buf.seek(0)
        df = pd.read_csv(buf, encoding="utf-8")
    # í•„ìš”í•œ íƒ€ì… ì •ë¦¬
    # ì‚¬ìš©ì›”: ì •ìˆ˜/ë¬¸ì â†’ 202501 ê°™ì€ í˜•íƒœ
    if "ì‚¬ìš©ì›”" in df.columns:
        df["ì‚¬ìš©ì›”"] = df["ì‚¬ìš©ì›”"].astype(str).str.replace(r"\D", "", regex=True).str[:6]
        # ê²°ì¸¡ í˜¹ì€ ë¹„ì •ìƒ ì œê±°
        df = df[df["ì‚¬ìš©ì›”"].str.len() == 6]
        df["ì‚¬ìš©ì›”"] = df["ì‚¬ìš©ì›”"].astype(int)
    # ì—´ ì´ë¦„ ì •ë¦¬ (ê³µë°± ì œê±°)
    df.columns = [c.strip() for c in df.columns]
    return df

if csv_bytes is None:
    st.info("ì¢Œì¸¡ì—ì„œ CSVë¥¼ ì„ íƒ/ì…ë ¥í•˜ì„¸ìš”. (ê¸°ë³¸ ê²½ë¡œê°€ ë³´ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥)")
    st.stop()

with st.spinner("CSV ë¡œë”© ì¤‘..."):
    df_raw = load_data(csv_bytes)

# ---------------------------
# ğŸ§¹ ì „ì²˜ë¦¬: Wide â†’ Long
# ---------------------------
@st.cache_data(show_spinner=True)
def to_long(df: pd.DataFrame) -> pd.DataFrame:
    # ì‹œê°„ëŒ€Â·ìŠ¹/í•˜ì°¨ ì—´ íƒì§€
    hour_cols = [c for c in df.columns if ("ìŠ¹ì°¨ì¸ì›" in c or "í•˜ì°¨ì¸ì›" in c)]
    id_cols = [c for c in ["ì‚¬ìš©ì›”", "í˜¸ì„ ëª…", "ì§€í•˜ì² ì—­", "ìš”ì¼", "ì‘ì—…ì¼ì"] if c in df.columns]

    # ì‹œê°„ëŒ€ ë¬¸ìì—´ ì§‘í•© (ì˜ˆ: "07ì‹œ-08ì‹œ")
    time_bins = sorted(set([c.split()[0] for c in hour_cols]),
                       key=lambda s: int(re.match(r"(\d+)", s).group(1)))

    # Long ë³€í™˜: ê° ì‹œê°„ëŒ€ì— ëŒ€í•´ ìŠ¹/í•˜ì°¨ë¥¼ í•œ ë²ˆì— ë¶™ì´ê¸°
    parts = []
    for t in time_bins:
        bcol = f"{t} ìŠ¹ì°¨ì¸ì›"
        acol = f"{t} í•˜ì°¨ì¸ì›"
        use_cols = [c for c in id_cols] + [bcol] + [acol]
        sub = df[use_cols].copy()
        sub["ì‹œê°„ëŒ€"] = t
        sub.rename(columns={bcol: "ìŠ¹ì°¨", acol: "í•˜ì°¨"}, inplace=True)
        parts.append(sub)

    long_df = pd.concat(parts, ignore_index=True)
    # ì‹œê°„ëŒ€ ì‹œì‘ ì‹œ(hour_start) ì¶”ì¶œ (ì˜ˆ: "07ì‹œ-08ì‹œ" â†’ 7)
    long_df["hour_start"] = long_df["ì‹œê°„ëŒ€"].str.extract(r"^(\d+)")
    long_df["hour_start"] = pd.to_numeric(long_df["hour_start"], errors="coerce").fillna(0).astype(int)
    # ë‹¤ìš´ìºìŠ¤íŒ…
    for col in ["ìŠ¹ì°¨", "í•˜ì°¨"]:
        long_df[col] = pd.to_numeric(long_df[col], errors="coerce").fillna(0).astype(np.int32)
    if "ì‚¬ìš©ì›”" in long_df.columns:
        long_df["ì‚¬ìš©ì›”"] = pd.to_numeric(long_df["ì‚¬ìš©ì›”"], errors="coerce").fillna(0).astype(np.int32)
    return long_df

with st.spinner("ì „ì²˜ë¦¬ ì¤‘ (Wide â†’ Long)â€¦"):
    df = to_long(df_raw)

# ë©”íƒ€ ì •ë³´
st.success(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,} í–‰ | ì»¬ëŸ¼: {list(df.columns)}")
with st.expander("ë°ì´í„° ì˜ˆì‹œ ë³´ê¸°", expanded=False):
    st.dataframe(df.head(20), use_container_width=True)

# ---------------------------
# ğŸ”§ í•™ìŠµ/ì˜ˆì¸¡ ìœ í‹¸
# ---------------------------
def pick_model(name: str):
    if name == "LightGBM (ìë™ ê¶Œì¥)" and LGBM_AVAILABLE:
        return LGBMRegressor(
            n_estimators=600,
            learning_rate=0.05,
            max_depth=-1,
            subsample=0.9,
            colsample_bytree=0.9,
            random_state=42
        )
    elif name.startswith("RandomForest"):
        return RandomForestRegressor(
            n_estimators=300,
            max_depth=None,
            n_jobs=-1,
            random_state=42
        )
    else:
        return LinearRegression()

def safe_label_encode(series: pd.Series):
    le = LabelEncoder()
    vals = series.fillna("N/A").astype(str)
    return le.fit_transform(vals), le

def rmse(y_true, y_pred):
    return np.sqrt(mean_squared_error(y_true, y_pred))

@st.cache_resource(show_spinner=True)
def train_models(df_long: pd.DataFrame, algo_name: str):
    # íŠ¹ì§•: í˜¸ì„ ëª…, ì§€í•˜ì² ì—­, hour_start, ì‚¬ìš©ì›”, (ê°€ëŠ¥í•˜ë©´ ìš”ì¼)
    feat_cols = []
    for c in ["í˜¸ì„ ëª…", "ì§€í•˜ì² ì—­", "hour_start", "ì‚¬ìš©ì›”"]:
        if c in df_long.columns:
            feat_cols.append(c)
    if "ìš”ì¼" in df_long.columns:
        feat_cols.append("ìš”ì¼")

    work = df_long[feat_cols + ["ìŠ¹ì°¨", "í•˜ì°¨"]].dropna().copy()

    # ì¸ì½”ë”©
    encoders = {}
    X = pd.DataFrame(index=work.index)
    for c in feat_cols:
        if work[c].dtype == "O":
            X[c], enc = safe_label_encode(work[c])
            encoders[c] = enc
        else:
            X[c] = work[c].astype(np.int32)

    # íƒ€ê²Ÿ(ìŠ¹ì°¨, í•˜ì°¨) ê°ê° ëª¨ë¸
    models = {}
    metrics = {}

    X_train, X_test, yb_train, yb_test = train_test_split(X, work["ìŠ¹ì°¨"], test_size=0.2, random_state=42)
    model_b = pick_model(algo_name)
    model_b.fit(X_train, yb_train)
    yb_pred = model_b.predict(X_test)
    metrics["ìŠ¹ì°¨_RMSE"] = rmse(yb_test, yb_pred)
    metrics["ìŠ¹ì°¨_MAE"]  = mean_absolute_error(yb_test, yb_pred)
    metrics["ìŠ¹ì°¨_R2"]   = r2_score(yb_test, yb_pred)
    models["ìŠ¹ì°¨"] = model_b

    X_train, X_test, ya_train, ya_test = train_test_split(X, work["í•˜ì°¨"], test_size=0.2, random_state=42)
    model_a = pick_model(algo_name)
    model_a.fit(X_train, ya_train)
    ya_pred = model_a.predict(X_test)
    metrics["í•˜ì°¨_RMSE"] = rmse(ya_test, ya_pred)
    metrics["í•˜ì°¨_MAE"]  = mean_absolute_error(ya_test, ya_pred)
    metrics["í•˜ì°¨_R2"]   = r2_score(ya_test, ya_pred)
    models["í•˜ì°¨"] = model_a

    return {
        "feat_cols": feat_cols,
        "encoders": encoders,
        "models": models,
        "metrics": metrics
    }

# ---------------------------
# ğŸ›ï¸ ì‚¬ì´ë“œë°”: ëª¨ë¸ ì„ íƒ/í•™ìŠµ
# ---------------------------
st.sidebar.header("2) ëª¨ë¸ í•™ìŠµ ì„¤ì •")
algo_name = st.sidebar.selectbox(
    "ì•Œê³ ë¦¬ì¦˜ ì„ íƒ",
    ["LightGBM (ìë™ ê¶Œì¥)"] + ["RandomForest (ëŒ€ì²´)", "LinearRegression (ê°„ë‹¨)"],
    index=0 if LGBM_AVAILABLE else 1
)
with st.sidebar:
    st.caption("ğŸ’¡ LightGBM ì„¤ì¹˜ ì•ˆë˜ì–´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ëŒ€ì²´ ëª¨ë¸ ì‚¬ìš©")

with st.spinner("ëª¨ë¸ í•™ìŠµ/ê²€ì¦ ì¤‘â€¦(ìºì‹œë¨)"):
    pack = train_models(df, algo_name)
st.sidebar.success("í•™ìŠµ ì™„ë£Œ!")
with st.sidebar.expander("í‰ê°€ì§€í‘œ (ê²€ì¦ì…‹)", expanded=False):
    st.json(pack["metrics"])

# ---------------------------
# ğŸ—ºï¸ ì…ë ¥ ìœ„ì ¯
# ---------------------------
st.header("ğŸ§® ì˜ˆì¸¡ ì…ë ¥")
cols = st.columns([1, 1, 1, 1.2, 1])
lines = sorted(df["í˜¸ì„ ëª…"].dropna().unique().tolist())
sel_line = cols[0].selectbox("í˜¸ì„ ", lines)

stations = sorted(df.loc[df["í˜¸ì„ ëª…"] == sel_line, "ì§€í•˜ì² ì—­"].dropna().unique().tolist())
sel_station = cols[1].selectbox("ì—­", stations)

# ë‚ ì§œ â†’ ì›”(YYYYMM)ë¡œ ë³€í™˜í•˜ì—¬ ì‚¬ìš©
sel_date = cols[2].date_input("ë‚ ì§œ ì„ íƒ", value=dt.date.today())
sel_month = int(sel_date.strftime("%Y%m"))
cols[2].caption(f"ì‚¬ìš©ì›”ë¡œ ë³€í™˜: **{sel_month}**")

# ì‹œê°„ëŒ€
time_bins = df["ì‹œê°„ëŒ€"].dropna().unique().tolist()
# ì‹œê°„ëŒ€ ìì—° ì •ë ¬
def hour_key(s): 
    m = re.match(r"(\d+)", s)
    return int(m.group(1)) if m else 0
time_bins = sorted(time_bins, key=hour_key)
sel_time = cols[3].selectbox("ì‹œê°„ëŒ€", time_bins)

# ìš”ì¼ (ë°ì´í„°ì— ìˆì„ ë•Œë§Œ ì‹¤ì œë¡œ ì‚¬ìš©)
weekday_options = ["ì›”","í™”","ìˆ˜","ëª©","ê¸ˆ","í† ","ì¼"]
sel_weekday = cols[4].selectbox("ìš”ì¼(ì„ íƒ)", options=["(ë¯¸ì‚¬ìš©)"]+weekday_options, index=0,
                               help="ë°ì´í„°ì— 'ìš”ì¼' ì»¬ëŸ¼ì´ ì¡´ì¬í•  ë•Œë§Œ ëª¨ë¸ì— ë°˜ì˜ë©ë‹ˆë‹¤.")

# ---------------------------
# ğŸ”® ì˜ˆì¸¡
# ---------------------------
def build_feature_row(pack, line, station, month, time_str, weekday):
    feat_cols = pack["feat_cols"]
    hour_start = int(re.match(r"(\d+)", time_str).group(1))
    row = {}
    for c in feat_cols:
        if c == "í˜¸ì„ ëª…":
            row[c] = line
        elif c == "ì§€í•˜ì² ì—­":
            row[c] = station
        elif c == "hour_start":
            row[c] = hour_start
        elif c == "ì‚¬ìš©ì›”":
            row[c] = month
        elif c == "ìš”ì¼":
            row[c] = weekday if weekday in weekday_options else "N/A"
    # ì¸ì½”ë”©
    X = {}
    for c in feat_cols:
        if c in pack["encoders"]:
            enc = pack["encoders"][c]
            X[c] = enc.transform([str(row.get(c, 'N/A'))])[0]
        else:
            X[c] = int(row.get(c, 0))
    return pd.DataFrame([X], columns=feat_cols)

colL, colR = st.columns([1,1])
with colL:
    if st.button("ğŸš€ ì˜ˆì¸¡ ì‹¤í–‰", use_container_width=True):
        X_row = build_feature_row(
            pack, sel_line, sel_station, sel_month, sel_time, sel_weekday
        )
        pred_board = float(pack["models"]["ìŠ¹ì°¨"].predict(X_row)[0])
        pred_alight = float(pack["models"]["í•˜ì°¨"].predict(X_row)[0])

        st.subheader("ğŸ“Œ ì˜ˆì¸¡ ê²°ê³¼")
        c1, c2 = st.columns(2)
        c1.metric("ì˜ˆìƒ **ìŠ¹ì°¨** ì¸ì›", f"{int(round(pred_board)):,} ëª…")
        c2.metric("ì˜ˆìƒ **í•˜ì°¨** ì¸ì›", f"{int(round(pred_alight)):,} ëª…")

        # ---------------------------
        # ğŸ“Š ë¹„êµ: ê³¼ê±° ë¶„í¬/í‰ê· 
        # ---------------------------
        st.markdown("---")
        st.subheader("ğŸ“ˆ ê³¼ê±° ë¶„í¬ì™€ ë¹„êµ")
        hist = df[(df["í˜¸ì„ ëª…"] == sel_line) & (df["ì§€í•˜ì² ì—­"] == sel_station) & (df["ì‹œê°„ëŒ€"] == sel_time)]
        if len(hist) > 0:
            # ì›”ë³„ í†µê³„
            grp = hist.groupby("ì‚¬ìš©ì›”", as_index=False)[["ìŠ¹ì°¨", "í•˜ì°¨"]].agg(["mean", "median", "min", "max"])
            grp.columns = [f"{a}_{b}" for a,b in grp.columns]
            grp = grp.reset_index().rename(columns={"index":"ì‚¬ìš©ì›”"})
            st.dataframe(grp.sort_values("ì‚¬ìš©ì›”", ascending=False), use_container_width=True)

            # Altair ì‹œê°í™” (Streamlit ê¸°ë³¸ ì§€ì›)
            import altair as alt
            line1 = alt.Chart(hist).mark_line(point=True).encode(
                x=alt.X("ì‚¬ìš©ì›”:O", title="ì‚¬ìš©ì›”(YYYYMM)"),
                y=alt.Y("ìŠ¹ì°¨:Q", title="ìŠ¹ì°¨ ì¸ì›"),
                tooltip=["ì‚¬ìš©ì›”","ìŠ¹ì°¨","í•˜ì°¨"]
            ).properties(height=280)
            line2 = alt.Chart(hist).mark_line(point=True).encode(
                x=alt.X("ì‚¬ìš©ì›”:O", title="ì‚¬ìš©ì›”(YYYYMM)"),
                y=alt.Y("í•˜ì°¨:Q", title="í•˜ì°¨ ì¸ì›"),
                tooltip=["ì‚¬ìš©ì›”","ìŠ¹ì°¨","í•˜ì°¨"]
            ).properties(height=280)
            st.altair_chart(line1, use_container_width=True)
            st.altair_chart(line2, use_container_width=True)

            # ì˜ˆì¸¡ì¹˜ vs ìµœê·¼ ì›” í‰ê·  ë¹„êµ
            recent_mean = hist[hist["ì‚¬ìš©ì›”"] >= (sel_month - 100)][["ìŠ¹ì°¨","í•˜ì°¨"]].mean()
            c1, c2, c3 = st.columns(3)
            c1.metric("ìµœê·¼ 1ë…„ í‰ê·  ìŠ¹ì°¨", f"{int(round(recent_mean['ìŠ¹ì°¨'])):,} ëª…" if not np.isnan(recent_mean["ìŠ¹ì°¨"]) else "ë°ì´í„° ì—†ìŒ")
            c2.metric("ìµœê·¼ 1ë…„ í‰ê·  í•˜ì°¨", f"{int(round(recent_mean['í•˜ì°¨'])):,} ëª…" if not np.isnan(recent_mean["í•˜ì°¨"]) else "ë°ì´í„° ì—†ìŒ")
            diff_b = (pred_board - (recent_mean["ìŠ¹ì°¨"] if not np.isnan(recent_mean["ìŠ¹ì°¨"]) else 0))
            diff_a = (pred_alight - (recent_mean["í•˜ì°¨"] if not np.isnan(recent_mean["í•˜ì°¨"]) else 0))
            c3.write(f"ì˜ˆì¸¡ì¹˜ ëŒ€ë¹„ ìµœê·¼ 1ë…„ í‰ê·  ì°¨ì´ â€” ìŠ¹ì°¨: **{diff_b:+.0f}ëª…**, í•˜ì°¨: **{diff_a:+.0f}ëª…**")
        else:
            st.info("ì„ íƒí•œ ì¡°í•©(í˜¸ì„ /ì—­/ì‹œê°„ëŒ€)ì— ëŒ€í•œ ê³¼ê±° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

with colR:
    # ê°„ë‹¨ EDA: ì„ íƒí•œ í˜¸ì„ ì˜ ì‹œê°„ëŒ€ë³„ í‰ê·  íˆíŠ¸ë§µ
    st.subheader("ğŸ§­ í˜¸ì„  ì‹œê°„ëŒ€ë³„ í‰ê·  (ê°„ë‹¨ EDA)")
    sub = df[df["í˜¸ì„ ëª…"] == sel_line]
    if len(sub) > 0:
        pivot_b = sub.pivot_table(index="ì§€í•˜ì² ì—­", columns="hour_start", values="ìŠ¹ì°¨", aggfunc="mean")
        pivot_a = sub.pivot_table(index="ì§€í•˜ì² ì—­", columns="hour_start", values="í•˜ì°¨", aggfunc="mean")
        st.caption("ìŠ¹ì°¨ í‰ê·  íˆíŠ¸ë§µ")
        st.dataframe(pivot_b.fillna(0).astype(int), use_container_width=True, height=300)
        st.caption("í•˜ì°¨ í‰ê·  íˆíŠ¸ë§µ")
        st.dataframe(pivot_a.fillna(0).astype(int), use_container_width=True, height=300)
    else:
        st.info("í•´ë‹¹ í˜¸ì„  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

st.markdown("---")
with st.expander("â„¹ï¸ ì£¼ì˜/ì„¤ëª…", expanded=False):
    st.markdown("""
- ì´ ë°ì´í„°ì…‹ì€ **ì›” ë‹¨ìœ„(`ì‚¬ìš©ì›”`)**ì™€ **ì‹œê°„ëŒ€(ì˜ˆ: `07ì‹œ-08ì‹œ`)** ì§‘ê³„ì…ë‹ˆë‹¤.  
- ê³µê°œ CSVì— **`ìš”ì¼` ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´** ìš”ì¼ ì…ë ¥ì€ **ì˜ˆì¸¡ì— ë°˜ì˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.** (UIì—ì„œë§Œ ì„ íƒ ê°€ëŠ¥)  
- LightGBM ë¯¸ì„¤ì¹˜ í™˜ê²½ì—ì„œëŠ” ìë™ìœ¼ë¡œ **RandomForest â†’ LinearRegression** ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.  
- ì˜ˆì¸¡ê°’ì€ ê³¼ê±° íŒ¨í„´ ê¸°ë°˜ í†µê³„ì  ì¶”ì •ì´ë¯€ë¡œ ì‹¤ì œ íƒ‘ìŠ¹ ìˆ˜ìš”ì™€ ì°¨ì´ê°€ ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
""")
